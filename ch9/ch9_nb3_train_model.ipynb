{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"border: 1px solid #e7692c; border-left: 15px solid #e7692c; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #e7692c\">Tip.</strong> <a style=\"color: #000000;\" href=\"https://nbviewer.jupyter.org/github/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/blob/master/ch9/ch9_nb3_train_model.ipynb\" title=\"View with Jupyter Online\">Click here to view this notebook on <code>nbviewer.jupyter.org</code></a>. \n",
    "    <br/>These notebooks are better read there, as Github default viewer ignores some of the formatting and interactive content.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T22:38:46.581850Z",
     "start_time": "2019-04-12T22:38:46.573807Z"
    }
   },
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "    <tr style=\"vertical-align: top; padding: 0; margin: 0;\">\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; padding-right: 15px;\">\n",
    "    <p style=\"background: #363636; color:#ffffff; text-align:justify; padding: 10px 25px;\">\n",
    "        <strong style=\"font-size: 1.0em;\"><span style=\"font-size: 1.2em;\"><span style=\"color: #e7692c;\">Hands-on</span> Computer Vision with TensorFlow 2</span><br/>by <em>Eliot Andres</em> & <em>Benjamin Planche</em> (Packt Pub.)</strong><br/><br/>\n",
    "        <strong>> Chapter 9: Performance and running on mobile</strong><br/>\n",
    "    </p>\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #e7692c;\">Notebook 3:</small><br/>Training a model and converting it for mobile devices</h1>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #363636; text-align:justify; padding: 0 10px;\">\n",
    "    In this chapter, we covered how to convert and run a model on mobile.\n",
    "<br/><br/>\n",
    "    This notebooks trains a model to recognize face expressions and converts it to CoreML, TFLite and TensorFlow.js\n",
    "</p>\n",
    "<br/>\n",
    "\n",
    "<p style=\"border-left: 15px solid #363636; text-align:justify; padding: 0 10px;\">\n",
    "    <strong> Requirements </strong>\n",
    "<br/><br/>\n",
    "    To run this notebook, you need to download the <a href=\"https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data\">FER dataset</a> and extract it. When done, change the `BASE_PATH` variable to point to the dataset folder.\n",
    "</p>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #e7692c; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #e7692c;\">Tip.</strong> The notebooks shared on this git repository illustrate some of notions from the book \"<em><strong>Hands-on Computer Vision with TensorFlow 2</strong></em>\" written by Eliot Andres and Benjamin Planche and published by Packt. If you enjoyed the insights shared here, <strong>please consider acquiring the book!</strong>\n",
    "<br/><br/>\n",
    "The book provides further guidance for those eager to learn about computer vision and to harness the power of TensorFlow 2 and Keras to build performant recognition systems for object detection, segmentation, video processing, smartphone applications, and more.</p>\n",
    "        </td>\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; width: 255px;\">\n",
    "    <a href=\"https://www.packtpub.com\" title=\"Buy on Packt!\">\n",
    "        <img src=\"../banner_images/book_cover.png\">\n",
    "    </a>\n",
    "    <p style=\"background: #e7692c; color:#ffffff; padding: 10px; text-align:justify;\"><strong>Leverage deep learning to create powerful image processing apps with TensorFlow 2 and Keras. <br/></strong>Get the book for more insights!</p>\n",
    "    <ul style=\"height: 32px; white-space: nowrap; text-align: center; margin: 0px; padding: 0px; padding-top: 10px;\">\n",
    "    <li style=\"display: inline-block; height: 100%; vertical-align: middle; float: left; margin: 5px; padding: 0px;\">\n",
    "        <a href=\"https://www.packtpub.com\" title=\"Get your Packt book!\">\n",
    "        <img style=\"vertical-align: middle; max-width: 75px; max-height: 32px;\" src=\"../banner_images/logo_packt.png\" width=\"75px\">\n",
    "        </a>\n",
    "    </li>\n",
    "    <li style=\"display: inline-block; height: 100%; vertical-align: middle; float: left; margin: 5px; padding: 0px;\">\n",
    "        <a href=\"https://www.packtpub.com\" title=\"Get the book on O'Reilly Safari!\">\n",
    "        <img style=\"vertical-align: middle; max-width: 75px; max-height: 32px;\" src=\"../banner_images/logo_oreilly.png\" width=\"75px\">\n",
    "        </a>\n",
    "    </li>\n",
    "    <li style=\"display: inline-block; height: 100%; vertical-align: middle; float: left; margin: 5px; padding: 0px;\">\n",
    "        <a href=\"https://www.packtpub.com\" title=\"Get the book on Amazon!\">\n",
    "        <img style=\"vertical-align: middle; max-width: 75px; max-height: 32px;\" src=\"../banner_images/logo_amazon.png\" width=\"75px\">\n",
    "        </a>\n",
    "    </li>\n",
    "    </ul>\n",
    "        </td>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T14:59:11.555911Z",
     "start_time": "2019-05-02T14:59:10.452013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-dev20190428'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set constants and parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T14:59:11.559813Z",
     "start_time": "2019-05-02T14:59:11.557198Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download data here: https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data\n",
    "DATASET_PATH = '../../backup_book/ch9/fer2013/fer2013.csv'\n",
    "\n",
    "IMAGE_SIZE = (48, 48)\n",
    "INPUT_SHAPE = IMAGE_SIZE + (1,)\n",
    "EMOTIONS = [\"angry\", \"disgust\", \"scared\",\n",
    "            \"happy\", \"sad\", \"surprised\", \"neutral\"]\n",
    "CALLBACK_PATIENCE = 50\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 110\n",
    "VALIDATION_SPLIT = .2\n",
    "NUM_CLASSES = len(EMOTIONS)\n",
    "L2_REGULARIZATION = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T14:59:13.433589Z",
     "start_time": "2019-05-02T14:59:11.560625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 48, 48, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 49, 49, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 24, 24, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 24, 24, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 24, 24, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 12, 12, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 12, 12, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 12, 12, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 12, 12, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 6, 6, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 6, 6, 256)         32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 6, 6, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 6, 6, 256)         65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 3, 3, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 3, 3, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 3, 3, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 3, 3, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 3, 3, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 3, 3, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 3, 3, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 1, 1, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 1, 1, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 1, 1, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 1, 1, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 3,235,463\n",
      "Trainable params: 3,213,575\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=INPUT_SHAPE)\n",
    "model = MobileNet(input_tensor=input_tensor, alpha=1.0,\n",
    "                    include_top=False, weights=None)\n",
    "\n",
    "output = tf.keras.layers.Reshape((1024,))(model.output)\n",
    "output = tf.keras.layers.Dense(7, activation='softmax')(output)\n",
    "model = tf.keras.Model(model.input, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T14:59:55.920285Z",
     "start_time": "2019-05-02T14:59:38.108478Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_fer2013():\n",
    "    data = pd.read_csv(DATASET_PATH)\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width, height = 48, 48\n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'), IMAGE_SIZE)\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces, -1)\n",
    "    emotions = pd.get_dummies(data['emotion']).values\n",
    "    return faces, emotions\n",
    "\n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    x = x - 0.5\n",
    "    x = x * 2.0\n",
    "    return x\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# loading dataset\n",
    "faces, emotions = load_fer2013()\n",
    "faces = preprocess_input(faces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T15:18:47.685515Z",
     "start_time": "2019-05-02T14:59:55.921463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "  1/897 [..............................] - ETA: 2:16:38 - loss: 2.4219 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0502 17:00:05.368174 139873498351360 callbacks.py:238] Method (on_train_batch_end) is slow compared to the batch update (0.111346). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/897 [==============================] - 34s 38ms/step - loss: 1.8895 - accuracy: 0.2381 - val_loss: 1.9825 - val_accuracy: 0.2403\n",
      "Epoch 2/110\n",
      "898/897 [==============================] - 21s 24ms/step - loss: 1.8195 - accuracy: 0.2617 - val_loss: 1.7785 - val_accuracy: 0.2657\n",
      "Epoch 3/110\n",
      "898/897 [==============================] - 21s 24ms/step - loss: 1.7751 - accuracy: 0.2925 - val_loss: 1.8008 - val_accuracy: 0.3476\n",
      "Epoch 4/110\n",
      "898/897 [==============================] - 21s 24ms/step - loss: 1.7257 - accuracy: 0.3233 - val_loss: 1.6124 - val_accuracy: 0.3817\n",
      "Epoch 5/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.6473 - accuracy: 0.3591 - val_loss: 1.6166 - val_accuracy: 0.3948\n",
      "Epoch 6/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.6021 - accuracy: 0.3778 - val_loss: 2.3959 - val_accuracy: 0.3362\n",
      "Epoch 7/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.5703 - accuracy: 0.3956 - val_loss: 1.5281 - val_accuracy: 0.4224\n",
      "Epoch 8/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.5270 - accuracy: 0.4099 - val_loss: 1.5633 - val_accuracy: 0.3986\n",
      "Epoch 9/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.4884 - accuracy: 0.4273 - val_loss: 1.3852 - val_accuracy: 0.4767\n",
      "Epoch 10/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.4448 - accuracy: 0.4446 - val_loss: 1.9072 - val_accuracy: 0.4132\n",
      "Epoch 11/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.4059 - accuracy: 0.4612 - val_loss: 1.3840 - val_accuracy: 0.4680\n",
      "Epoch 12/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.3553 - accuracy: 0.4791 - val_loss: 1.3591 - val_accuracy: 0.4788\n",
      "Epoch 13/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.3478 - accuracy: 0.4829 - val_loss: 1.5023 - val_accuracy: 0.4203\n",
      "Epoch 14/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.3387 - accuracy: 0.4880 - val_loss: 1.3802 - val_accuracy: 0.4845\n",
      "Epoch 15/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.3423 - accuracy: 0.4847 - val_loss: 1.2625 - val_accuracy: 0.5323\n",
      "Epoch 16/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.2798 - accuracy: 0.5121 - val_loss: 1.2671 - val_accuracy: 0.5242\n",
      "Epoch 17/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.2428 - accuracy: 0.5282 - val_loss: 1.2173 - val_accuracy: 0.5403\n",
      "Epoch 18/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.2266 - accuracy: 0.5344 - val_loss: 1.2719 - val_accuracy: 0.5064\n",
      "Epoch 19/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.2068 - accuracy: 0.5419 - val_loss: 1.2165 - val_accuracy: 0.5479\n",
      "Epoch 20/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.1839 - accuracy: 0.5537 - val_loss: 1.1463 - val_accuracy: 0.5692\n",
      "Epoch 21/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.1605 - accuracy: 0.5595 - val_loss: 1.1564 - val_accuracy: 0.5691\n",
      "Epoch 22/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.1492 - accuracy: 0.5642 - val_loss: 1.1215 - val_accuracy: 0.5811\n",
      "Epoch 23/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.1346 - accuracy: 0.5694 - val_loss: 1.1179 - val_accuracy: 0.5729\n",
      "Epoch 24/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.1193 - accuracy: 0.5766 - val_loss: 1.1002 - val_accuracy: 0.5908\n",
      "Epoch 25/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.1096 - accuracy: 0.5859 - val_loss: 1.1187 - val_accuracy: 0.5853\n",
      "Epoch 26/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0924 - accuracy: 0.5891 - val_loss: 1.0815 - val_accuracy: 0.5977\n",
      "Epoch 27/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0807 - accuracy: 0.5949 - val_loss: 1.1265 - val_accuracy: 0.5872\n",
      "Epoch 28/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0731 - accuracy: 0.5959 - val_loss: 1.1094 - val_accuracy: 0.5836\n",
      "Epoch 29/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0641 - accuracy: 0.6008 - val_loss: 1.1124 - val_accuracy: 0.5911\n",
      "Epoch 30/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0501 - accuracy: 0.6065 - val_loss: 1.0488 - val_accuracy: 0.6140\n",
      "Epoch 31/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0340 - accuracy: 0.6104 - val_loss: 1.0493 - val_accuracy: 0.6121\n",
      "Epoch 32/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0326 - accuracy: 0.6134 - val_loss: 1.0333 - val_accuracy: 0.6096\n",
      "Epoch 33/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0164 - accuracy: 0.6214 - val_loss: 1.0497 - val_accuracy: 0.6067\n",
      "Epoch 34/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0060 - accuracy: 0.6205 - val_loss: 1.0374 - val_accuracy: 0.6128\n",
      "Epoch 35/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0035 - accuracy: 0.6261 - val_loss: 1.0332 - val_accuracy: 0.6194\n",
      "Epoch 36/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9890 - accuracy: 0.6290 - val_loss: 1.0174 - val_accuracy: 0.6258\n",
      "Epoch 37/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9806 - accuracy: 0.6328 - val_loss: 1.0634 - val_accuracy: 0.6073\n",
      "Epoch 38/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9709 - accuracy: 0.6379 - val_loss: 1.0248 - val_accuracy: 0.6216\n",
      "Epoch 39/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9655 - accuracy: 0.6391 - val_loss: 1.0228 - val_accuracy: 0.6181\n",
      "Epoch 40/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9832 - accuracy: 0.6349 - val_loss: 1.5155 - val_accuracy: 0.4370\n",
      "Epoch 41/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 1.0470 - accuracy: 0.6064 - val_loss: 1.0093 - val_accuracy: 0.6282\n",
      "Epoch 42/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9602 - accuracy: 0.6403 - val_loss: 0.9897 - val_accuracy: 0.6317\n",
      "Epoch 43/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9368 - accuracy: 0.6506 - val_loss: 0.9841 - val_accuracy: 0.6408\n",
      "Epoch 44/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9233 - accuracy: 0.6562 - val_loss: 1.0084 - val_accuracy: 0.6314\n",
      "Epoch 45/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9199 - accuracy: 0.6582 - val_loss: 1.0071 - val_accuracy: 0.6262\n",
      "Epoch 46/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9232 - accuracy: 0.6564 - val_loss: 1.1412 - val_accuracy: 0.5790\n",
      "Epoch 47/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9273 - accuracy: 0.6536 - val_loss: 1.0202 - val_accuracy: 0.6250\n",
      "Epoch 48/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9138 - accuracy: 0.6571 - val_loss: 1.0181 - val_accuracy: 0.6248\n",
      "Epoch 49/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9045 - accuracy: 0.6623 - val_loss: 1.0257 - val_accuracy: 0.6276\n",
      "Epoch 50/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.9023 - accuracy: 0.6621 - val_loss: 0.9923 - val_accuracy: 0.6330\n",
      "Epoch 51/110\n",
      "898/897 [==============================] - 22s 24ms/step - loss: 0.8986 - accuracy: 0.6647 - val_loss: 0.9862 - val_accuracy: 0.6393\n",
      "Epoch 52/110\n",
      "546/897 [=================>............] - ETA: 8s - loss: 0.8809 - accuracy: 0.6698"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d43287df97b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     validation_data=(xtest, ytest))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1527\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1270\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3275\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3277\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3278\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    548\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 549\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    420\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    421\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 422\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    423\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regularization = tf.keras.regularizers.l2(L2_REGULARIZATION)\n",
    "\n",
    "early_stop = EarlyStopping('val_loss', patience=CALLBACK_PATIENCE)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    'val_loss', factor=0.1, patience=int(CALLBACK_PATIENCE/4), verbose=1)\n",
    "tensorboard = TensorBoard('./logs')\n",
    "callbacks = [early_stop, reduce_lr, tensorboard]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.2)\n",
    "\n",
    "model.fit_generator(data_generator.flow(xtrain, ytrain, BATCH_SIZE),\n",
    "                    steps_per_epoch=len(xtrain) / BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS, verbose=1, callbacks=callbacks,\n",
    "                    validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T15:19:04.323641Z",
     "start_time": "2019-05-02T15:18:53.238962Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0502 17:18:53.262634 139873498351360 __init__.py:118] TensorFlow version 2.0.0-dev20190428 detected. Last version known to be fully compatible is 1.12.0 .\n",
      "W0502 17:18:58.839174 139873498351360 deprecation.py:323] From /root/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0502 17:18:58.839908 139873498351360 tf_logging.py:161] Export includes no default signature!\n",
      "W0502 17:19:01.555757 139873498351360 tf_logging.py:161] Export includes no default signature!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_node_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8c63b6000ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m freeze_graph.freeze_graph(input_graph_filename, input_saver_def_path,\n\u001b[0;32m---> 24\u001b[0;31m                           \u001b[0minput_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_node_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                           \u001b[0mrestore_op_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                           \u001b[0;34m'frozen_model.pb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_node_names' is not defined"
     ]
    }
   ],
   "source": [
    "import tfcoreml as tf_converter\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "input_saved_model_dir = \"./saved_model\"\n",
    "\n",
    "tf.keras.experimental.export_saved_model(\n",
    "    model, saved_model_path=input_saved_model_dir, serving_only=False)\n",
    "\n",
    "\n",
    "output_node_name = 'dense/Softmax'\n",
    "input_binary = False\n",
    "input_saver_def_path = False\n",
    "restore_op_name = None\n",
    "filename_tensor_name = None\n",
    "clear_devices = True\n",
    "input_meta_graph = False\n",
    "checkpoint_path = None\n",
    "input_graph_filename = None\n",
    "saved_model_tags = tag_constants.SERVING\n",
    "\n",
    "\n",
    "freeze_graph.freeze_graph(input_graph_filename, input_saver_def_path,\n",
    "                          input_binary, checkpoint_path, output_node_names,\n",
    "                          restore_op_name, filename_tensor_name,\n",
    "                          'frozen_model.pb', clear_devices, \"\", \"\", \"\",\n",
    "                          input_meta_graph, input_saved_model_dir,\n",
    "                          saved_model_tags)\n",
    "\n",
    "\n",
    "tf_converter.convert('frozen_model.pb',\n",
    "                     'mobilenet.mlmodel',\n",
    "                     class_labels=EMOTIONS,\n",
    "                     image_input_names=['input_1:0'],\n",
    "                     output_feature_names=[output_node_name + ':0'],\n",
    "                     red_bias=-1,\n",
    "                     green_bias=-1,\n",
    "                     blue_bias=-1,\n",
    "                     image_scale=1/127.5,\n",
    "                     is_bgr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-02T08:26:46.529117Z",
     "start_time": "2019-05-02T08:26:44.129147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12822216"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "## Or from a SavedModel\n",
    "# converter = tf.lite.TFLiteConverter('./saved_model')\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open(\"result.tflite\", \"wb\").write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert in the current environment\n",
    "import sys\n",
    "!{sys.executable} tensorflowjs_converter --input_format=tf_saved_model saved_model my-tfjs --output_format tfjs_graph_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
