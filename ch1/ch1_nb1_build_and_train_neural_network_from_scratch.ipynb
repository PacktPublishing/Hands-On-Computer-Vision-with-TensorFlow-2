{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p style=\"border: 1px solid #e7692c; border-left: 15px solid #e7692c; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #e7692c\">Tip.</strong> <a style=\"color: #000000;\" href=\"https://nbviewer.jupyter.org/github/PacktPublishing/Hands-On-Computer-Vision-with-Tensorflow/blob/master/ch1/ch1_nb1_build_and_train_neural_network_from_scratch.ipynb\" title=\"View with Jupyter Online\">Click here to view this notebook on <code>nbviewer.jupyter.org</code></a>. \n",
    "    <br/>These notebooks are better read there, as Github default viewer ignores/breaks some content.\n",
    "    </p>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "<div style=\"background: #363636; color:#ffffff; padding:.8em; text-align:justify;\">\n",
    "    <p>\n",
    "        <strong style=\"font-size: 1.2em;\"><span style=\"font-size: 1.5em;\"><span style=\"color: #e7692c;\">Hands-on</span> Computer Vision with TensorFlow 2</span><br/>by <em>Eliot Andres</em> & <em>Benjamin Planche</em> (Packt Pub.)</strong><br/><br/>\n",
    "        <strong>> Chapter 1: Computer Vision and Neural Networks</strong><br/>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<h1 style=\"color: #e7692c;\"> Building and Training a Neural Network from Scratch</h1>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #363636; text-align:justify; font-size: 1.1em; padding: 0 10px\">\n",
    "    In this introductory chapter, we learned more about <em>Computer Vision</em>, <em>Deep Learning</em>, and <em>how neural networks work</em>.\n",
    "<br/><br/>\n",
    "    To better grasp these concepts before switching to TensorFlow, we described how to build our own simple neural network from scratch, and apply it to a classification task. In this notebook, we quickly present an overview of the code and results explained in the book.\n",
    "</p>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #e7692c; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #e7692c;\">Learn more!</strong> The notebooks shared on this git repository illustrate some of notions from the book \"<em><strong>Hands-on Computer Vision with TensorFlow 2</strong></em>\" written by Eliot Andres and Benjamin Planche and published by Packt. If you enjoyed the insights shared here, <strong>please consider acquiring the book!</strong>\n",
    "<br/><br/>\n",
    "The book provides further guidance for those eager to learn about computer vision and to harness the power of TensorFlow 2 and Keras to build performant recognition systems for object detection, segmentation, video processing, smartphone applications, and more.</p>\n",
    "        </td>\n",
    "        <td>\n",
    "<div style=\"float: right; width: 255px;\">\n",
    "    <a href=\"https://www.packtpub.com\" title=\"Buy on Packt!\">\n",
    "        <img src=\"../banner_images/book_cover.png\">\n",
    "    </a>\n",
    "    <p style=\"background: #e7692c; color:#ffffff; padding:.8em; text-align:justify;\"><strong>Leverage deep learning to create powerful image processing apps with TensorFlow 2 and Keras. <br/></strong>Get the book for more insights!</p>\n",
    "    <p style=\"height: 32px; white-space: nowrap; text-align: center;\">\n",
    "    <a style=\"display: inline-block; height: 100%; vertical-align: middle; float: left; margin: 5px;\" href=\"https://www.packtpub.com\" title=\"Get your Packt book!\">\n",
    "        <img style=\"vertical-align: middle; max-width: 75px; max-height: 32px;\" src=\"../banner_images/logo_packt.png\" width=\"75px\">\n",
    "    </a>\n",
    "    <a style=\"display: inline-block; height: 100%; vertical-align: middle; float: left; margin: 5px;\" href=\"https://www.packtpub.com\" title=\"Get the book on O'Reilly Safari!\">\n",
    "        <img style=\"vertical-align: middle; max-width: 75px; max-height: 32px;\" src=\"../banner_images/logo_oreilly.png\" width=\"75px\">\n",
    "    </a>\n",
    "    <a style=\"display: inline-block; height: 100%; vertical-align: middle; float: left; margin: 5px;\" href=\"https://www.packtpub.com\" title=\"Get the book on Amazon!\">\n",
    "        <img style=\"vertical-align: middle; max-width: 75px; max-height: 32px;\" src=\"../banner_images/logo_amazon.png\" width=\"75px\">\n",
    "    </a>\n",
    "    </p>\n",
    "</div>\n",
    "        </td>\n",
    "        </tr>\n",
    "        </table>\n",
    "\n",
    "<div style=\"float: right; width: 255px;\">\n",
    "    <a href=\"https://www.packtpub.com\" title=\"Buy on Packt!\">\n",
    "        <img src=\"../banner_images/book_cover.png\">\n",
    "    </a>\n",
    "    <p style=\"background: #e7692c; color:#ffffff; padding:.8em; text-align:justify;\"><strong>Leverage deep learning to create powerful image processing apps with TensorFlow 2 and Keras. <br/></strong>Get the book for more insights!</p>\n",
    "    <p style=\"height: 32px; white-space: nowrap; text-align: center;\">\n",
    "    <a style=\"display: inline-block; height: 100%; vertical-align: middle; float: left; margin: 5px;\" href=\"https://www.packtpub.com\" title=\"Get your Packt book!\">\n",
    "        <img style=\"vertical-align: middle; max-width: 75px; max-height: 32px;\" src=\"../banner_images/logo_packt.png\" width=\"75px\">\n",
    "    </a>\n",
    "    <a style=\"display: inline-block; height: 100%; vertical-align: middle; float: left; margin: 5px;\" href=\"https://www.packtpub.com\" title=\"Get the book on O'Reilly Safari!\">\n",
    "        <img style=\"vertical-align: middle; max-width: 75px; max-height: 32px;\" src=\"../banner_images/logo_oreilly.png\" width=\"75px\">\n",
    "    </a>\n",
    "    <a style=\"display: inline-block; height: 100%; vertical-align: middle; float: left; margin: 5px;\" href=\"https://www.packtpub.com\" title=\"Get the book on Amazon!\">\n",
    "        <img style=\"vertical-align: middle; max-width: 75px; max-height: 32px;\" src=\"../banner_images/logo_amazon.png\" width=\"75px\">\n",
    "    </a>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #363636; color:#ffffff; padding:.8em; text-align:justify; margin-right: 270px;\">\n",
    "    <p>\n",
    "        <strong style=\"font-size: 1.2em;\"><span style=\"font-size: 1.5em;\"><span style=\"color: #e7692c;\">Hands-on</span> Computer Vision with TensorFlow 2</span><br/>by <em>Eliot Andres</em> & <em>Benjamin Planche</em> (Packt Pub.)</strong><br/><br/>\n",
    "        <strong>> Chapter 1: Computer Vision and Neural Networks</strong><br/>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<h1 style=\"color: #e7692c;\"> Building and Training a Neural Network from Scratch</h1>\n",
    "\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #363636; margin-right: 270px; text-align:justify; font-size: 1.1em; padding: 0 10px\">\n",
    "    In this introductory chapter, we learned more about <em>Computer Vision</em>, <em>Deep Learning</em>, and <em>how neural networks work</em>.\n",
    "<br/><br/>\n",
    "    To better grasp these concepts before switching to TensorFlow, we described how to build our own simple neural network from scratch, and apply it to a classification task. In this notebook, we quickly present an overview of the code and results explained in the book.\n",
    "</p>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #e7692c; margin-right: 270px; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #e7692c;\">Learn more!</strong> The notebooks shared on this git repository illustrate some of notions from the book \"<em><strong>Hands-on Computer Vision with TensorFlow 2</strong></em>\" written by Eliot Andres and Benjamin Planche and published by Packt. If you enjoyed the insights shared here, <strong>please consider acquiring the book!</strong>\n",
    "<br/><br/>\n",
    "The book provides further guidance for those eager to learn about computer vision and to harness the power of TensorFlow 2 and Keras to build performant recognition systems for object detection, segmentation, video processing, smartphone applications, and more.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At the Beginning: the Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[neuron.py](neuron.py) contains our implementation of a single *artificial neuron* able to process and forward information. Let's demonstrate how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      # We use numpy to make vector and matrix computations easy.\n",
    "from neuron import Neuron\n",
    "np.random.seed(42)      # Fixing the seed for the random number generation, to get reproducable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we instantiate our neuron. Let's create a *perceptron* taking 2 input values, and using the step function for computing its *activation*. Its weights and bias values are randomly set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron's random weights = [ 0.37454012  0.95071431  0.73199394] , and random bias = [ 0.59865848]\n"
     ]
    }
   ],
   "source": [
    "input_size = 3\n",
    "step_function = lambda y: 0 if y <= 0 else 1\n",
    "\n",
    "perceptron = Neuron(num_inputs=input_size, activation_function=step_function)\n",
    "print(\"Perceptron's random weights = {} , and random bias = {}\".format(perceptron.W, perceptron.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly generate a random input vector of 3 value (i.e. a column-vector of (shape = `(1, 3)`), to be fed to our neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15601864  0.15599452  0.05808361]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(input_size).reshape(1, input_size)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now feed our perceptron with this input and display the corresponding activation. We invite our readers to try different inputs or edit the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layering Neurons Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we presented how neurons can be organized into layers, with the corresponding class implemented in [fully_connected_layer.py](fully_connected_layer.py). Once again, let's quickly show how this *layer* can be used to process input values, one by one or stacked together as *batches*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fully_connected_layer import FullyConnectedLayer\n",
    "np.random.seed(42)      # Fixing the seed again, to get reproducable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a layer of 3 neurons (so 3 output values), taking 2 input values and applying this time the ReLU (Rectified Linear Unit) function for the activations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "num_neurons = 3\n",
    "relu_function = lambda y: np.maximum(y, 0)\n",
    "\n",
    "layer = FullyConnectedLayer(num_inputs=input_size, layer_size=num_neurons, activation_function=relu_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly generate 2 random input vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.63635007, -0.63319098]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.random.uniform(-1, 1, 2).reshape(1, 2)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39151551,  0.04951286]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = np.random.uniform(-1, 1, 2).reshape(1, 2)\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our layer can either process them separetely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29875996,  1.00368303,  0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.forward(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.46015109,  0.80997374,  0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.forward(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29875996,  1.00368303,  0.        ],\n",
       "       [ 1.46015109,  0.80997374,  0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x12 = np.concatenate((x1, x2))  # stack of input vectors, of shape `(2, 2)`\n",
    "layer.forward(x12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying our Network to Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using untrained perceptrons and layers on random inputs is however a bit dull. In this final section of the notebook, we cover the application of our simple model to the hand-written digit classification task (on the [MNIST dataset](http://yann.lecun.com/exdb/mnist)) presented in the book.\n",
    "\n",
    "[simple_network.py](simple_network.py) wraps everything together into a modular *neural network* model with the optimization process described along the chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing a solution, let's prepare the data, loading the MNIST data for training and testing methods. For simplicity, we will use the Python module [`mnist`](https://github.com/datapythonista/mnist) developed by [Marc Garcia](https://github.com/datapythonista), and already installed in this chapter's directory (see [`./mnist/`](mnist/__init__.py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib    # we also import matplotlib, to visualize some data and results\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `python-mnist` module makes it simple to load the training and testing data (images and their labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = mnist.train_images(), mnist.train_labels()\n",
    "X_test,  y_test  = mnist.test_images(), mnist.test_labels()\n",
    "num_classes = 10    # classes are the digits from 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big are our training and testing datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. we have 60,000 training samples and 10,000 testing one, with each sample an image of 28 by 28 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the data, for instance using `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xef56ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_idx = np.random.randint(0, X_train.shape[0])\n",
    "plt.imshow(X_train[img_idx], cmap=matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[img_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... Our images match their label, which is good news!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as our network only accepts column vectors, we need to \"flatten\" the images into 1D vector, i.e. vectors of shape `(1, 784)` (since 28 * 28 = 784):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.reshape(-1, 28 * 28), X_test.reshape(-1, 28 * 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's have a look at our pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel values between 0 and 255\n"
     ]
    }
   ],
   "source": [
    "print(\"Pixel values between {} and {}\".format(X_train.min(), X_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are normal interger values for images with 8 bits per channel (`uint8`)... These values may be however too big for some of our operations. For instance, given a too big input value, our sigmoid may return a `nan` value (because of the exponential function it uses, which may \"overflow\" with a large input value).\n",
    "\n",
    "It is thus customary to *normalize* the input data, i.e. to scale the values between 0 and 1 (or -1 and 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized pixel values between 0.0 and 1.0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = X_train / 255., X_test / 255.\n",
    "print(\"Normalized pixel values between {} and {}\".format(X_train.min(), X_train.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to compute the loss, we need to \"one-hot\" the labels, e.g. converting the label `4` into `[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.eye(num_classes)[y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, all the NN logic explained in the book is implemented in [simple_network.py](simple_network.py).\n",
    "Let's use it to instantiate a network with 2 hidden layers, taking a flattened image as input and returning a 10-value vector representing its belief the image belongs to each of the class (the highter the value,the stronger the belief): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from simple_network import SimpleNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier = SimpleNetwork(num_inputs=X_train.shape[1], num_outputs=num_classes, hidden_layers_sizes=[64, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check how our network performs (computing its *loss* over the training set, and its *accuracy* over the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained : training loss = 4.436700 | val accuracy = 12.19%\n"
     ]
    }
   ],
   "source": [
    "predictions = mnist_classifier.forward(X_train)                         # forward pass\n",
    "loss_untrained = mnist_classifier.loss_function(predictions, y_train)   # loss computation\n",
    "\n",
    "accuracy_untrained = mnist_classifier.evaluate_accuracy(X_test, y_test)  # Accuracy\n",
    "print(\"Untrained : training loss = {:.6f} | val accuracy = {:.2f}%\".format(loss_untrained, accuracy_untrained * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the answer is: it performs really poorly... But as we know from the book, this is to be expected: we have yet to train our network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teaching our Network to Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where things finally get interesting. As the whole training procedure is already explained and implemented (c.f. [simple_network.py](simple_network.py)), we simply have to launch it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0: training loss = 1.096978 | val accuracy = 19.10%\n",
      "Epoch    1: training loss = 0.886127 | val accuracy = 32.17%\n",
      "Epoch    2: training loss = 0.785361 | val accuracy = 44.06%\n",
      "Epoch    3: training loss = 0.695873 | val accuracy = 50.68%\n",
      "Epoch    4: training loss = 0.630815 | val accuracy = 56.25%\n",
      "Epoch    5: training loss = 0.576848 | val accuracy = 61.30%\n",
      "Epoch    6: training loss = 0.519389 | val accuracy = 67.69%\n",
      "Epoch    7: training loss = 0.465288 | val accuracy = 71.35%\n",
      "Epoch    8: training loss = 0.426172 | val accuracy = 74.30%\n",
      "Epoch    9: training loss = 0.396564 | val accuracy = 76.31%\n",
      "Epoch   10: training loss = 0.372741 | val accuracy = 77.75%\n",
      "Epoch   11: training loss = 0.352826 | val accuracy = 78.98%\n",
      "Epoch   12: training loss = 0.335768 | val accuracy = 80.12%\n",
      "Epoch   13: training loss = 0.320914 | val accuracy = 81.04%\n",
      "Epoch   14: training loss = 0.307823 | val accuracy = 81.87%\n",
      "Epoch   15: training loss = 0.296183 | val accuracy = 82.44%\n",
      "Epoch   16: training loss = 0.285757 | val accuracy = 83.13%\n",
      "Epoch   17: training loss = 0.276360 | val accuracy = 83.53%\n",
      "Epoch   18: training loss = 0.267840 | val accuracy = 84.04%\n",
      "Epoch   19: training loss = 0.260072 | val accuracy = 84.50%\n",
      "Epoch   20: training loss = 0.252953 | val accuracy = 84.89%\n",
      "Epoch   21: training loss = 0.246398 | val accuracy = 85.41%\n",
      "Epoch   22: training loss = 0.240340 | val accuracy = 85.78%\n",
      "Epoch   23: training loss = 0.234725 | val accuracy = 86.11%\n",
      "Epoch   24: training loss = 0.229506 | val accuracy = 86.29%\n",
      "Epoch   25: training loss = 0.224643 | val accuracy = 86.54%\n",
      "Epoch   26: training loss = 0.220102 | val accuracy = 86.82%\n",
      "Epoch   27: training loss = 0.215849 | val accuracy = 87.09%\n",
      "Epoch   28: training loss = 0.211858 | val accuracy = 87.29%\n",
      "Epoch   29: training loss = 0.208103 | val accuracy = 87.49%\n",
      "Epoch   30: training loss = 0.204562 | val accuracy = 87.65%\n",
      "Epoch   31: training loss = 0.201216 | val accuracy = 87.79%\n",
      "Epoch   32: training loss = 0.198046 | val accuracy = 87.91%\n",
      "Epoch   33: training loss = 0.195038 | val accuracy = 88.05%\n",
      "Epoch   34: training loss = 0.192176 | val accuracy = 88.19%\n",
      "Epoch   35: training loss = 0.189451 | val accuracy = 88.38%\n",
      "Epoch   36: training loss = 0.186851 | val accuracy = 88.47%\n",
      "Epoch   37: training loss = 0.184367 | val accuracy = 88.64%\n",
      "Epoch   38: training loss = 0.181991 | val accuracy = 88.74%\n",
      "Epoch   39: training loss = 0.179715 | val accuracy = 88.84%\n",
      "Epoch   40: training loss = 0.177532 | val accuracy = 88.92%\n",
      "Epoch   41: training loss = 0.175435 | val accuracy = 89.01%\n",
      "Epoch   42: training loss = 0.173420 | val accuracy = 89.06%\n",
      "Epoch   43: training loss = 0.171481 | val accuracy = 89.22%\n",
      "Epoch   44: training loss = 0.169612 | val accuracy = 89.27%\n",
      "Epoch   45: training loss = 0.167811 | val accuracy = 89.37%\n",
      "Epoch   46: training loss = 0.166071 | val accuracy = 89.41%\n",
      "Epoch   47: training loss = 0.164391 | val accuracy = 89.49%\n",
      "Epoch   48: training loss = 0.162767 | val accuracy = 89.58%\n",
      "Epoch   49: training loss = 0.161194 | val accuracy = 89.64%\n",
      "Epoch   50: training loss = 0.159670 | val accuracy = 89.79%\n",
      "Epoch   51: training loss = 0.158192 | val accuracy = 89.89%\n",
      "Epoch   52: training loss = 0.156757 | val accuracy = 89.97%\n",
      "Epoch   53: training loss = 0.155363 | val accuracy = 90.01%\n",
      "Epoch   54: training loss = 0.154007 | val accuracy = 90.05%\n",
      "Epoch   55: training loss = 0.152688 | val accuracy = 90.15%\n",
      "Epoch   56: training loss = 0.151404 | val accuracy = 90.19%\n",
      "Epoch   57: training loss = 0.150155 | val accuracy = 90.21%\n",
      "Epoch   58: training loss = 0.148938 | val accuracy = 90.28%\n",
      "Epoch   59: training loss = 0.147752 | val accuracy = 90.37%\n",
      "Epoch   60: training loss = 0.146596 | val accuracy = 90.50%\n",
      "Epoch   61: training loss = 0.145469 | val accuracy = 90.60%\n",
      "Epoch   62: training loss = 0.144369 | val accuracy = 90.67%\n",
      "Epoch   63: training loss = 0.143296 | val accuracy = 90.67%\n",
      "Epoch   64: training loss = 0.142247 | val accuracy = 90.74%\n",
      "Epoch   65: training loss = 0.141222 | val accuracy = 90.83%\n",
      "Epoch   66: training loss = 0.140220 | val accuracy = 90.84%\n",
      "Epoch   67: training loss = 0.139239 | val accuracy = 90.85%\n",
      "Epoch   68: training loss = 0.138279 | val accuracy = 90.93%\n",
      "Epoch   69: training loss = 0.137338 | val accuracy = 90.97%\n",
      "Epoch   70: training loss = 0.136417 | val accuracy = 90.99%\n",
      "Epoch   71: training loss = 0.135513 | val accuracy = 91.02%\n",
      "Epoch   72: training loss = 0.134627 | val accuracy = 91.05%\n",
      "Epoch   73: training loss = 0.133757 | val accuracy = 91.06%\n",
      "Epoch   74: training loss = 0.132902 | val accuracy = 91.11%\n",
      "Epoch   75: training loss = 0.132063 | val accuracy = 91.13%\n",
      "Epoch   76: training loss = 0.131239 | val accuracy = 91.15%\n",
      "Epoch   77: training loss = 0.130428 | val accuracy = 91.20%\n",
      "Epoch   78: training loss = 0.129631 | val accuracy = 91.25%\n",
      "Epoch   79: training loss = 0.128846 | val accuracy = 91.27%\n",
      "Epoch   80: training loss = 0.128075 | val accuracy = 91.29%\n",
      "Epoch   81: training loss = 0.127315 | val accuracy = 91.30%\n",
      "Epoch   82: training loss = 0.126567 | val accuracy = 91.35%\n",
      "Epoch   83: training loss = 0.125831 | val accuracy = 91.41%\n",
      "Epoch   84: training loss = 0.125106 | val accuracy = 91.46%\n",
      "Epoch   85: training loss = 0.124391 | val accuracy = 91.51%\n",
      "Epoch   86: training loss = 0.123687 | val accuracy = 91.52%\n",
      "Epoch   87: training loss = 0.122993 | val accuracy = 91.58%\n",
      "Epoch   88: training loss = 0.122309 | val accuracy = 91.63%\n",
      "Epoch   89: training loss = 0.121634 | val accuracy = 91.69%\n",
      "Epoch   90: training loss = 0.120968 | val accuracy = 91.71%\n",
      "Epoch   91: training loss = 0.120311 | val accuracy = 91.71%\n",
      "Epoch   92: training loss = 0.119663 | val accuracy = 91.73%\n",
      "Epoch   93: training loss = 0.119023 | val accuracy = 91.77%\n",
      "Epoch   94: training loss = 0.118391 | val accuracy = 91.76%\n",
      "Epoch   95: training loss = 0.117768 | val accuracy = 91.82%\n",
      "Epoch   96: training loss = 0.117153 | val accuracy = 91.87%\n",
      "Epoch   97: training loss = 0.116545 | val accuracy = 91.92%\n",
      "Epoch   98: training loss = 0.115946 | val accuracy = 91.91%\n",
      "Epoch   99: training loss = 0.115354 | val accuracy = 91.97%\n",
      "Epoch  100: training loss = 0.114770 | val accuracy = 92.01%\n",
      "Epoch  101: training loss = 0.114193 | val accuracy = 92.02%\n",
      "Epoch  102: training loss = 0.113624 | val accuracy = 92.04%\n",
      "Epoch  103: training loss = 0.113063 | val accuracy = 92.08%\n",
      "Epoch  104: training loss = 0.112509 | val accuracy = 92.12%\n",
      "Epoch  105: training loss = 0.111962 | val accuracy = 92.15%\n",
      "Epoch  106: training loss = 0.111423 | val accuracy = 92.19%\n",
      "Epoch  107: training loss = 0.110891 | val accuracy = 92.19%\n",
      "Epoch  108: training loss = 0.110366 | val accuracy = 92.20%\n",
      "Epoch  109: training loss = 0.109848 | val accuracy = 92.21%\n",
      "Epoch  110: training loss = 0.109337 | val accuracy = 92.23%\n",
      "Epoch  111: training loss = 0.108833 | val accuracy = 92.25%\n",
      "Epoch  112: training loss = 0.108335 | val accuracy = 92.25%\n",
      "Epoch  113: training loss = 0.107844 | val accuracy = 92.29%\n",
      "Epoch  114: training loss = 0.107360 | val accuracy = 92.32%\n",
      "Epoch  115: training loss = 0.106882 | val accuracy = 92.36%\n",
      "Epoch  116: training loss = 0.106411 | val accuracy = 92.39%\n",
      "Epoch  117: training loss = 0.105945 | val accuracy = 92.38%\n",
      "Epoch  118: training loss = 0.105486 | val accuracy = 92.37%\n",
      "Epoch  119: training loss = 0.105033 | val accuracy = 92.37%\n",
      "Epoch  120: training loss = 0.104585 | val accuracy = 92.39%\n",
      "Epoch  121: training loss = 0.104143 | val accuracy = 92.40%\n",
      "Epoch  122: training loss = 0.103707 | val accuracy = 92.39%\n",
      "Epoch  123: training loss = 0.103275 | val accuracy = 92.40%\n",
      "Epoch  124: training loss = 0.102850 | val accuracy = 92.42%\n",
      "Epoch  125: training loss = 0.102429 | val accuracy = 92.44%\n",
      "Epoch  126: training loss = 0.102014 | val accuracy = 92.45%\n",
      "Epoch  127: training loss = 0.101603 | val accuracy = 92.44%\n",
      "Epoch  128: training loss = 0.101197 | val accuracy = 92.45%\n",
      "Epoch  129: training loss = 0.100796 | val accuracy = 92.47%\n",
      "Epoch  130: training loss = 0.100400 | val accuracy = 92.49%\n",
      "Epoch  131: training loss = 0.100007 | val accuracy = 92.54%\n",
      "Epoch  132: training loss = 0.099620 | val accuracy = 92.56%\n",
      "Epoch  133: training loss = 0.099236 | val accuracy = 92.57%\n",
      "Epoch  134: training loss = 0.098857 | val accuracy = 92.60%\n",
      "Epoch  135: training loss = 0.098482 | val accuracy = 92.63%\n",
      "Epoch  136: training loss = 0.098111 | val accuracy = 92.64%\n",
      "Epoch  137: training loss = 0.097743 | val accuracy = 92.68%\n",
      "Epoch  138: training loss = 0.097380 | val accuracy = 92.74%\n",
      "Epoch  139: training loss = 0.097020 | val accuracy = 92.75%\n",
      "Epoch  140: training loss = 0.096663 | val accuracy = 92.74%\n",
      "Epoch  141: training loss = 0.096310 | val accuracy = 92.79%\n",
      "Epoch  142: training loss = 0.095961 | val accuracy = 92.85%\n",
      "Epoch  143: training loss = 0.095615 | val accuracy = 92.87%\n",
      "Epoch  144: training loss = 0.095272 | val accuracy = 92.91%\n",
      "Epoch  145: training loss = 0.094932 | val accuracy = 92.92%\n",
      "Epoch  146: training loss = 0.094596 | val accuracy = 92.91%\n",
      "Epoch  147: training loss = 0.094262 | val accuracy = 92.91%\n",
      "Epoch  148: training loss = 0.093932 | val accuracy = 92.95%\n",
      "Epoch  149: training loss = 0.093604 | val accuracy = 92.93%\n",
      "Epoch  150: training loss = 0.093280 | val accuracy = 92.95%\n",
      "Epoch  151: training loss = 0.092958 | val accuracy = 92.96%\n",
      "Epoch  152: training loss = 0.092638 | val accuracy = 92.98%\n",
      "Epoch  153: training loss = 0.092322 | val accuracy = 92.99%\n",
      "Epoch  154: training loss = 0.092008 | val accuracy = 93.01%\n",
      "Epoch  155: training loss = 0.091697 | val accuracy = 93.05%\n",
      "Epoch  156: training loss = 0.091388 | val accuracy = 93.06%\n",
      "Epoch  157: training loss = 0.091081 | val accuracy = 93.06%\n",
      "Epoch  158: training loss = 0.090777 | val accuracy = 93.07%\n",
      "Epoch  159: training loss = 0.090476 | val accuracy = 93.07%\n",
      "Epoch  160: training loss = 0.090176 | val accuracy = 93.06%\n",
      "Epoch  161: training loss = 0.089879 | val accuracy = 93.09%\n",
      "Epoch  162: training loss = 0.089584 | val accuracy = 93.09%\n",
      "Epoch  163: training loss = 0.089292 | val accuracy = 93.10%\n",
      "Epoch  164: training loss = 0.089001 | val accuracy = 93.11%\n",
      "Epoch  165: training loss = 0.088713 | val accuracy = 93.09%\n",
      "Epoch  166: training loss = 0.088427 | val accuracy = 93.10%\n",
      "Epoch  167: training loss = 0.088143 | val accuracy = 93.10%\n",
      "Epoch  168: training loss = 0.087861 | val accuracy = 93.12%\n",
      "Epoch  169: training loss = 0.087581 | val accuracy = 93.12%\n",
      "Epoch  170: training loss = 0.087303 | val accuracy = 93.11%\n",
      "Epoch  171: training loss = 0.087027 | val accuracy = 93.12%\n",
      "Epoch  172: training loss = 0.086753 | val accuracy = 93.13%\n",
      "Epoch  173: training loss = 0.086481 | val accuracy = 93.15%\n",
      "Epoch  174: training loss = 0.086211 | val accuracy = 93.14%\n",
      "Epoch  175: training loss = 0.085943 | val accuracy = 93.14%\n",
      "Epoch  176: training loss = 0.085677 | val accuracy = 93.17%\n",
      "Epoch  177: training loss = 0.085412 | val accuracy = 93.15%\n",
      "Epoch  178: training loss = 0.085150 | val accuracy = 93.17%\n",
      "Epoch  179: training loss = 0.084889 | val accuracy = 93.19%\n",
      "Epoch  180: training loss = 0.084631 | val accuracy = 93.22%\n",
      "Epoch  181: training loss = 0.084374 | val accuracy = 93.23%\n",
      "Epoch  182: training loss = 0.084119 | val accuracy = 93.22%\n",
      "Epoch  183: training loss = 0.083866 | val accuracy = 93.23%\n",
      "Epoch  184: training loss = 0.083614 | val accuracy = 93.24%\n",
      "Epoch  185: training loss = 0.083364 | val accuracy = 93.26%\n",
      "Epoch  186: training loss = 0.083116 | val accuracy = 93.26%\n",
      "Epoch  187: training loss = 0.082870 | val accuracy = 93.27%\n",
      "Epoch  188: training loss = 0.082626 | val accuracy = 93.28%\n",
      "Epoch  189: training loss = 0.082383 | val accuracy = 93.29%\n",
      "Epoch  190: training loss = 0.082142 | val accuracy = 93.30%\n",
      "Epoch  191: training loss = 0.081902 | val accuracy = 93.33%\n",
      "Epoch  192: training loss = 0.081664 | val accuracy = 93.36%\n",
      "Epoch  193: training loss = 0.081428 | val accuracy = 93.35%\n",
      "Epoch  194: training loss = 0.081194 | val accuracy = 93.35%\n",
      "Epoch  195: training loss = 0.080961 | val accuracy = 93.37%\n",
      "Epoch  196: training loss = 0.080729 | val accuracy = 93.38%\n",
      "Epoch  197: training loss = 0.080500 | val accuracy = 93.39%\n",
      "Epoch  198: training loss = 0.080271 | val accuracy = 93.41%\n",
      "Epoch  199: training loss = 0.080045 | val accuracy = 93.44%\n",
      "Epoch  200: training loss = 0.079820 | val accuracy = 93.46%\n",
      "Epoch  201: training loss = 0.079596 | val accuracy = 93.46%\n",
      "Epoch  202: training loss = 0.079375 | val accuracy = 93.51%\n",
      "Epoch  203: training loss = 0.079154 | val accuracy = 93.54%\n",
      "Epoch  204: training loss = 0.078935 | val accuracy = 93.55%\n",
      "Epoch  205: training loss = 0.078718 | val accuracy = 93.54%\n",
      "Epoch  206: training loss = 0.078502 | val accuracy = 93.56%\n",
      "Epoch  207: training loss = 0.078287 | val accuracy = 93.56%\n",
      "Epoch  208: training loss = 0.078074 | val accuracy = 93.57%\n",
      "Epoch  209: training loss = 0.077863 | val accuracy = 93.58%\n",
      "Epoch  210: training loss = 0.077652 | val accuracy = 93.59%\n",
      "Epoch  211: training loss = 0.077443 | val accuracy = 93.59%\n",
      "Epoch  212: training loss = 0.077236 | val accuracy = 93.59%\n",
      "Epoch  213: training loss = 0.077030 | val accuracy = 93.61%\n",
      "Epoch  214: training loss = 0.076825 | val accuracy = 93.63%\n",
      "Epoch  215: training loss = 0.076622 | val accuracy = 93.63%\n",
      "Epoch  216: training loss = 0.076420 | val accuracy = 93.64%\n",
      "Epoch  217: training loss = 0.076219 | val accuracy = 93.63%\n",
      "Epoch  218: training loss = 0.076020 | val accuracy = 93.65%\n",
      "Epoch  219: training loss = 0.075821 | val accuracy = 93.65%\n",
      "Epoch  220: training loss = 0.075625 | val accuracy = 93.66%\n",
      "Epoch  221: training loss = 0.075429 | val accuracy = 93.65%\n",
      "Epoch  222: training loss = 0.075235 | val accuracy = 93.65%\n",
      "Epoch  223: training loss = 0.075042 | val accuracy = 93.68%\n",
      "Epoch  224: training loss = 0.074850 | val accuracy = 93.70%\n",
      "Epoch  225: training loss = 0.074660 | val accuracy = 93.72%\n",
      "Epoch  226: training loss = 0.074471 | val accuracy = 93.72%\n",
      "Epoch  227: training loss = 0.074283 | val accuracy = 93.72%\n",
      "Epoch  228: training loss = 0.074096 | val accuracy = 93.73%\n",
      "Epoch  229: training loss = 0.073910 | val accuracy = 93.72%\n",
      "Epoch  230: training loss = 0.073726 | val accuracy = 93.72%\n",
      "Epoch  231: training loss = 0.073542 | val accuracy = 93.71%\n",
      "Epoch  232: training loss = 0.073360 | val accuracy = 93.71%\n",
      "Epoch  233: training loss = 0.073179 | val accuracy = 93.72%\n",
      "Epoch  234: training loss = 0.072999 | val accuracy = 93.73%\n",
      "Epoch  235: training loss = 0.072820 | val accuracy = 93.75%\n",
      "Epoch  236: training loss = 0.072642 | val accuracy = 93.75%\n",
      "Epoch  237: training loss = 0.072465 | val accuracy = 93.75%\n",
      "Epoch  238: training loss = 0.072290 | val accuracy = 93.73%\n",
      "Epoch  239: training loss = 0.072115 | val accuracy = 93.73%\n",
      "Epoch  240: training loss = 0.071941 | val accuracy = 93.72%\n",
      "Epoch  241: training loss = 0.071768 | val accuracy = 93.71%\n",
      "Epoch  242: training loss = 0.071596 | val accuracy = 93.74%\n",
      "Epoch  243: training loss = 0.071426 | val accuracy = 93.74%\n",
      "Epoch  244: training loss = 0.071256 | val accuracy = 93.75%\n",
      "Epoch  245: training loss = 0.071087 | val accuracy = 93.77%\n",
      "Epoch  246: training loss = 0.070919 | val accuracy = 93.78%\n",
      "Epoch  247: training loss = 0.070753 | val accuracy = 93.78%\n",
      "Epoch  248: training loss = 0.070587 | val accuracy = 93.79%\n",
      "Epoch  249: training loss = 0.070422 | val accuracy = 93.81%\n",
      "Epoch  250: training loss = 0.070259 | val accuracy = 93.81%\n",
      "Epoch  251: training loss = 0.070096 | val accuracy = 93.84%\n",
      "Epoch  252: training loss = 0.069935 | val accuracy = 93.85%\n",
      "Epoch  253: training loss = 0.069775 | val accuracy = 93.86%\n",
      "Epoch  254: training loss = 0.069615 | val accuracy = 93.86%\n",
      "Epoch  255: training loss = 0.069457 | val accuracy = 93.86%\n",
      "Epoch  256: training loss = 0.069300 | val accuracy = 93.86%\n",
      "Epoch  257: training loss = 0.069144 | val accuracy = 93.87%\n",
      "Epoch  258: training loss = 0.068988 | val accuracy = 93.89%\n",
      "Epoch  259: training loss = 0.068834 | val accuracy = 93.92%\n",
      "Epoch  260: training loss = 0.068681 | val accuracy = 93.93%\n",
      "Epoch  261: training loss = 0.068529 | val accuracy = 93.95%\n",
      "Epoch  262: training loss = 0.068377 | val accuracy = 93.96%\n",
      "Epoch  263: training loss = 0.068227 | val accuracy = 93.96%\n",
      "Epoch  264: training loss = 0.068077 | val accuracy = 93.98%\n",
      "Epoch  265: training loss = 0.067928 | val accuracy = 93.98%\n",
      "Epoch  266: training loss = 0.067781 | val accuracy = 93.99%\n",
      "Epoch  267: training loss = 0.067634 | val accuracy = 93.99%\n",
      "Epoch  268: training loss = 0.067488 | val accuracy = 94.02%\n",
      "Epoch  269: training loss = 0.067342 | val accuracy = 94.03%\n",
      "Epoch  270: training loss = 0.067198 | val accuracy = 94.06%\n",
      "Epoch  271: training loss = 0.067054 | val accuracy = 94.06%\n",
      "Epoch  272: training loss = 0.066911 | val accuracy = 94.07%\n",
      "Epoch  273: training loss = 0.066769 | val accuracy = 94.08%\n",
      "Epoch  274: training loss = 0.066628 | val accuracy = 94.08%\n",
      "Epoch  275: training loss = 0.066487 | val accuracy = 94.08%\n",
      "Epoch  276: training loss = 0.066347 | val accuracy = 94.09%\n",
      "Epoch  277: training loss = 0.066208 | val accuracy = 94.10%\n",
      "Epoch  278: training loss = 0.066070 | val accuracy = 94.10%\n",
      "Epoch  279: training loss = 0.065932 | val accuracy = 94.10%\n",
      "Epoch  280: training loss = 0.065795 | val accuracy = 94.12%\n",
      "Epoch  281: training loss = 0.065659 | val accuracy = 94.13%\n",
      "Epoch  282: training loss = 0.065524 | val accuracy = 94.15%\n",
      "Epoch  283: training loss = 0.065389 | val accuracy = 94.14%\n",
      "Epoch  284: training loss = 0.065255 | val accuracy = 94.14%\n",
      "Epoch  285: training loss = 0.065121 | val accuracy = 94.15%\n",
      "Epoch  286: training loss = 0.064988 | val accuracy = 94.15%\n",
      "Epoch  287: training loss = 0.064856 | val accuracy = 94.16%\n",
      "Epoch  288: training loss = 0.064724 | val accuracy = 94.16%\n",
      "Epoch  289: training loss = 0.064593 | val accuracy = 94.16%\n",
      "Epoch  290: training loss = 0.064463 | val accuracy = 94.17%\n",
      "Epoch  291: training loss = 0.064333 | val accuracy = 94.17%\n",
      "Epoch  292: training loss = 0.064204 | val accuracy = 94.17%\n",
      "Epoch  293: training loss = 0.064076 | val accuracy = 94.23%\n",
      "Epoch  294: training loss = 0.063948 | val accuracy = 94.23%\n",
      "Epoch  295: training loss = 0.063821 | val accuracy = 94.24%\n",
      "Epoch  296: training loss = 0.063694 | val accuracy = 94.25%\n",
      "Epoch  297: training loss = 0.063568 | val accuracy = 94.26%\n",
      "Epoch  298: training loss = 0.063443 | val accuracy = 94.28%\n",
      "Epoch  299: training loss = 0.063319 | val accuracy = 94.28%\n",
      "Epoch  300: training loss = 0.063194 | val accuracy = 94.28%\n",
      "Epoch  301: training loss = 0.063071 | val accuracy = 94.28%\n",
      "Epoch  302: training loss = 0.062948 | val accuracy = 94.29%\n",
      "Epoch  303: training loss = 0.062826 | val accuracy = 94.28%\n",
      "Epoch  304: training loss = 0.062704 | val accuracy = 94.28%\n",
      "Epoch  305: training loss = 0.062583 | val accuracy = 94.29%\n",
      "Epoch  306: training loss = 0.062463 | val accuracy = 94.29%\n",
      "Epoch  307: training loss = 0.062343 | val accuracy = 94.30%\n",
      "Epoch  308: training loss = 0.062224 | val accuracy = 94.31%\n",
      "Epoch  309: training loss = 0.062105 | val accuracy = 94.31%\n",
      "Epoch  310: training loss = 0.061987 | val accuracy = 94.31%\n",
      "Epoch  311: training loss = 0.061869 | val accuracy = 94.32%\n",
      "Epoch  312: training loss = 0.061752 | val accuracy = 94.32%\n",
      "Epoch  313: training loss = 0.061635 | val accuracy = 94.31%\n",
      "Epoch  314: training loss = 0.061519 | val accuracy = 94.33%\n",
      "Epoch  315: training loss = 0.061403 | val accuracy = 94.33%\n",
      "Epoch  316: training loss = 0.061288 | val accuracy = 94.33%\n",
      "Epoch  317: training loss = 0.061174 | val accuracy = 94.34%\n",
      "Epoch  318: training loss = 0.061060 | val accuracy = 94.36%\n",
      "Epoch  319: training loss = 0.060946 | val accuracy = 94.38%\n",
      "Epoch  320: training loss = 0.060833 | val accuracy = 94.38%\n",
      "Epoch  321: training loss = 0.060720 | val accuracy = 94.40%\n",
      "Epoch  322: training loss = 0.060607 | val accuracy = 94.39%\n",
      "Epoch  323: training loss = 0.060495 | val accuracy = 94.39%\n",
      "Epoch  324: training loss = 0.060384 | val accuracy = 94.40%\n",
      "Epoch  325: training loss = 0.060273 | val accuracy = 94.41%\n",
      "Epoch  326: training loss = 0.060162 | val accuracy = 94.42%\n",
      "Epoch  327: training loss = 0.060052 | val accuracy = 94.43%\n",
      "Epoch  328: training loss = 0.059942 | val accuracy = 94.43%\n",
      "Epoch  329: training loss = 0.059832 | val accuracy = 94.44%\n",
      "Epoch  330: training loss = 0.059723 | val accuracy = 94.44%\n",
      "Epoch  331: training loss = 0.059614 | val accuracy = 94.44%\n",
      "Epoch  332: training loss = 0.059506 | val accuracy = 94.44%\n",
      "Epoch  333: training loss = 0.059398 | val accuracy = 94.44%\n",
      "Epoch  334: training loss = 0.059290 | val accuracy = 94.44%\n",
      "Epoch  335: training loss = 0.059183 | val accuracy = 94.44%\n",
      "Epoch  336: training loss = 0.059076 | val accuracy = 94.43%\n",
      "Epoch  337: training loss = 0.058969 | val accuracy = 94.42%\n",
      "Epoch  338: training loss = 0.058863 | val accuracy = 94.43%\n",
      "Epoch  339: training loss = 0.058757 | val accuracy = 94.43%\n",
      "Epoch  340: training loss = 0.058652 | val accuracy = 94.44%\n",
      "Epoch  341: training loss = 0.058547 | val accuracy = 94.42%\n",
      "Epoch  342: training loss = 0.058442 | val accuracy = 94.43%\n",
      "Epoch  343: training loss = 0.058338 | val accuracy = 94.43%\n",
      "Epoch  344: training loss = 0.058234 | val accuracy = 94.45%\n",
      "Epoch  345: training loss = 0.058130 | val accuracy = 94.47%\n",
      "Epoch  346: training loss = 0.058027 | val accuracy = 94.47%\n",
      "Epoch  347: training loss = 0.057924 | val accuracy = 94.47%\n",
      "Epoch  348: training loss = 0.057822 | val accuracy = 94.48%\n",
      "Epoch  349: training loss = 0.057720 | val accuracy = 94.49%\n",
      "Epoch  350: training loss = 0.057619 | val accuracy = 94.51%\n",
      "Epoch  351: training loss = 0.057517 | val accuracy = 94.50%\n",
      "Epoch  352: training loss = 0.057417 | val accuracy = 94.50%\n",
      "Epoch  353: training loss = 0.057316 | val accuracy = 94.50%\n",
      "Epoch  354: training loss = 0.057216 | val accuracy = 94.50%\n",
      "Epoch  355: training loss = 0.057117 | val accuracy = 94.51%\n",
      "Epoch  356: training loss = 0.057018 | val accuracy = 94.49%\n",
      "Epoch  357: training loss = 0.056919 | val accuracy = 94.49%\n",
      "Epoch  358: training loss = 0.056820 | val accuracy = 94.49%\n",
      "Epoch  359: training loss = 0.056722 | val accuracy = 94.50%\n",
      "Epoch  360: training loss = 0.056625 | val accuracy = 94.50%\n",
      "Epoch  361: training loss = 0.056528 | val accuracy = 94.50%\n",
      "Epoch  362: training loss = 0.056431 | val accuracy = 94.50%\n",
      "Epoch  363: training loss = 0.056334 | val accuracy = 94.50%\n",
      "Epoch  364: training loss = 0.056238 | val accuracy = 94.50%\n",
      "Epoch  365: training loss = 0.056143 | val accuracy = 94.50%\n",
      "Epoch  366: training loss = 0.056047 | val accuracy = 94.50%\n",
      "Epoch  367: training loss = 0.055952 | val accuracy = 94.50%\n",
      "Epoch  368: training loss = 0.055858 | val accuracy = 94.50%\n",
      "Epoch  369: training loss = 0.055763 | val accuracy = 94.49%\n",
      "Epoch  370: training loss = 0.055669 | val accuracy = 94.49%\n",
      "Epoch  371: training loss = 0.055576 | val accuracy = 94.49%\n",
      "Epoch  372: training loss = 0.055483 | val accuracy = 94.49%\n",
      "Epoch  373: training loss = 0.055390 | val accuracy = 94.49%\n",
      "Epoch  374: training loss = 0.055297 | val accuracy = 94.48%\n",
      "Epoch  375: training loss = 0.055205 | val accuracy = 94.48%\n",
      "Epoch  376: training loss = 0.055113 | val accuracy = 94.49%\n",
      "Epoch  377: training loss = 0.055021 | val accuracy = 94.49%\n",
      "Epoch  378: training loss = 0.054930 | val accuracy = 94.50%\n",
      "Epoch  379: training loss = 0.054839 | val accuracy = 94.49%\n",
      "Epoch  380: training loss = 0.054748 | val accuracy = 94.48%\n",
      "Epoch  381: training loss = 0.054658 | val accuracy = 94.48%\n",
      "Epoch  382: training loss = 0.054568 | val accuracy = 94.49%\n",
      "Epoch  383: training loss = 0.054478 | val accuracy = 94.50%\n",
      "Epoch  384: training loss = 0.054388 | val accuracy = 94.49%\n",
      "Epoch  385: training loss = 0.054299 | val accuracy = 94.50%\n",
      "Epoch  386: training loss = 0.054210 | val accuracy = 94.51%\n",
      "Epoch  387: training loss = 0.054122 | val accuracy = 94.51%\n",
      "Epoch  388: training loss = 0.054034 | val accuracy = 94.52%\n",
      "Epoch  389: training loss = 0.053946 | val accuracy = 94.52%\n",
      "Epoch  390: training loss = 0.053858 | val accuracy = 94.52%\n",
      "Epoch  391: training loss = 0.053771 | val accuracy = 94.52%\n",
      "Epoch  392: training loss = 0.053684 | val accuracy = 94.52%\n",
      "Epoch  393: training loss = 0.053597 | val accuracy = 94.53%\n",
      "Epoch  394: training loss = 0.053510 | val accuracy = 94.53%\n",
      "Epoch  395: training loss = 0.053424 | val accuracy = 94.54%\n",
      "Epoch  396: training loss = 0.053338 | val accuracy = 94.54%\n",
      "Epoch  397: training loss = 0.053252 | val accuracy = 94.54%\n",
      "Epoch  398: training loss = 0.053167 | val accuracy = 94.53%\n",
      "Epoch  399: training loss = 0.053082 | val accuracy = 94.54%\n",
      "Epoch  400: training loss = 0.052997 | val accuracy = 94.54%\n",
      "Epoch  401: training loss = 0.052912 | val accuracy = 94.53%\n",
      "Epoch  402: training loss = 0.052828 | val accuracy = 94.54%\n",
      "Epoch  403: training loss = 0.052744 | val accuracy = 94.53%\n",
      "Epoch  404: training loss = 0.052660 | val accuracy = 94.53%\n",
      "Epoch  405: training loss = 0.052576 | val accuracy = 94.52%\n",
      "Epoch  406: training loss = 0.052493 | val accuracy = 94.53%\n",
      "Epoch  407: training loss = 0.052410 | val accuracy = 94.53%\n",
      "Epoch  408: training loss = 0.052327 | val accuracy = 94.55%\n",
      "Epoch  409: training loss = 0.052245 | val accuracy = 94.55%\n",
      "Epoch  410: training loss = 0.052162 | val accuracy = 94.53%\n",
      "Epoch  411: training loss = 0.052080 | val accuracy = 94.53%\n",
      "Epoch  412: training loss = 0.051998 | val accuracy = 94.53%\n",
      "Epoch  413: training loss = 0.051917 | val accuracy = 94.53%\n",
      "Epoch  414: training loss = 0.051836 | val accuracy = 94.53%\n",
      "Epoch  415: training loss = 0.051755 | val accuracy = 94.52%\n",
      "Epoch  416: training loss = 0.051674 | val accuracy = 94.51%\n",
      "Epoch  417: training loss = 0.051594 | val accuracy = 94.51%\n",
      "Epoch  418: training loss = 0.051514 | val accuracy = 94.51%\n",
      "Epoch  419: training loss = 0.051434 | val accuracy = 94.51%\n",
      "Epoch  420: training loss = 0.051355 | val accuracy = 94.51%\n",
      "Epoch  421: training loss = 0.051276 | val accuracy = 94.53%\n",
      "Epoch  422: training loss = 0.051197 | val accuracy = 94.52%\n",
      "Epoch  423: training loss = 0.051119 | val accuracy = 94.52%\n",
      "Epoch  424: training loss = 0.051041 | val accuracy = 94.53%\n",
      "Epoch  425: training loss = 0.050963 | val accuracy = 94.54%\n",
      "Epoch  426: training loss = 0.050886 | val accuracy = 94.55%\n",
      "Epoch  427: training loss = 0.050808 | val accuracy = 94.56%\n",
      "Epoch  428: training loss = 0.050732 | val accuracy = 94.56%\n",
      "Epoch  429: training loss = 0.050655 | val accuracy = 94.55%\n",
      "Epoch  430: training loss = 0.050579 | val accuracy = 94.56%\n",
      "Epoch  431: training loss = 0.050504 | val accuracy = 94.57%\n",
      "Epoch  432: training loss = 0.050428 | val accuracy = 94.57%\n",
      "Epoch  433: training loss = 0.050353 | val accuracy = 94.58%\n",
      "Epoch  434: training loss = 0.050279 | val accuracy = 94.59%\n",
      "Epoch  435: training loss = 0.050204 | val accuracy = 94.59%\n",
      "Epoch  436: training loss = 0.050130 | val accuracy = 94.59%\n",
      "Epoch  437: training loss = 0.050056 | val accuracy = 94.59%\n",
      "Epoch  438: training loss = 0.049983 | val accuracy = 94.60%\n",
      "Epoch  439: training loss = 0.049909 | val accuracy = 94.60%\n",
      "Epoch  440: training loss = 0.049836 | val accuracy = 94.60%\n",
      "Epoch  441: training loss = 0.049764 | val accuracy = 94.60%\n",
      "Epoch  442: training loss = 0.049691 | val accuracy = 94.60%\n",
      "Epoch  443: training loss = 0.049619 | val accuracy = 94.61%\n",
      "Epoch  444: training loss = 0.049547 | val accuracy = 94.61%\n",
      "Epoch  445: training loss = 0.049476 | val accuracy = 94.60%\n",
      "Epoch  446: training loss = 0.049404 | val accuracy = 94.60%\n",
      "Epoch  447: training loss = 0.049333 | val accuracy = 94.60%\n",
      "Epoch  448: training loss = 0.049262 | val accuracy = 94.61%\n",
      "Epoch  449: training loss = 0.049192 | val accuracy = 94.61%\n",
      "Epoch  450: training loss = 0.049121 | val accuracy = 94.61%\n",
      "Epoch  451: training loss = 0.049051 | val accuracy = 94.61%\n",
      "Epoch  452: training loss = 0.048982 | val accuracy = 94.61%\n",
      "Epoch  453: training loss = 0.048912 | val accuracy = 94.63%\n",
      "Epoch  454: training loss = 0.048843 | val accuracy = 94.63%\n",
      "Epoch  455: training loss = 0.048774 | val accuracy = 94.64%\n",
      "Epoch  456: training loss = 0.048705 | val accuracy = 94.65%\n",
      "Epoch  457: training loss = 0.048636 | val accuracy = 94.65%\n",
      "Epoch  458: training loss = 0.048568 | val accuracy = 94.67%\n",
      "Epoch  459: training loss = 0.048500 | val accuracy = 94.69%\n",
      "Epoch  460: training loss = 0.048432 | val accuracy = 94.69%\n",
      "Epoch  461: training loss = 0.048364 | val accuracy = 94.69%\n",
      "Epoch  462: training loss = 0.048297 | val accuracy = 94.69%\n",
      "Epoch  463: training loss = 0.048230 | val accuracy = 94.71%\n",
      "Epoch  464: training loss = 0.048163 | val accuracy = 94.72%\n",
      "Epoch  465: training loss = 0.048096 | val accuracy = 94.73%\n",
      "Epoch  466: training loss = 0.048030 | val accuracy = 94.73%\n",
      "Epoch  467: training loss = 0.047964 | val accuracy = 94.74%\n",
      "Epoch  468: training loss = 0.047898 | val accuracy = 94.74%\n",
      "Epoch  469: training loss = 0.047833 | val accuracy = 94.74%\n",
      "Epoch  470: training loss = 0.047767 | val accuracy = 94.75%\n",
      "Epoch  471: training loss = 0.047702 | val accuracy = 94.76%\n",
      "Epoch  472: training loss = 0.047637 | val accuracy = 94.76%\n",
      "Epoch  473: training loss = 0.047572 | val accuracy = 94.75%\n",
      "Epoch  474: training loss = 0.047508 | val accuracy = 94.75%\n",
      "Epoch  475: training loss = 0.047444 | val accuracy = 94.75%\n",
      "Epoch  476: training loss = 0.047380 | val accuracy = 94.75%\n",
      "Epoch  477: training loss = 0.047316 | val accuracy = 94.76%\n",
      "Epoch  478: training loss = 0.047252 | val accuracy = 94.76%\n",
      "Epoch  479: training loss = 0.047189 | val accuracy = 94.76%\n",
      "Epoch  480: training loss = 0.047126 | val accuracy = 94.76%\n",
      "Epoch  481: training loss = 0.047063 | val accuracy = 94.77%\n",
      "Epoch  482: training loss = 0.047000 | val accuracy = 94.77%\n",
      "Epoch  483: training loss = 0.046938 | val accuracy = 94.77%\n",
      "Epoch  484: training loss = 0.046876 | val accuracy = 94.77%\n",
      "Epoch  485: training loss = 0.046814 | val accuracy = 94.79%\n",
      "Epoch  486: training loss = 0.046752 | val accuracy = 94.79%\n",
      "Epoch  487: training loss = 0.046690 | val accuracy = 94.80%\n",
      "Epoch  488: training loss = 0.046628 | val accuracy = 94.80%\n",
      "Epoch  489: training loss = 0.046567 | val accuracy = 94.80%\n",
      "Epoch  490: training loss = 0.046506 | val accuracy = 94.79%\n",
      "Epoch  491: training loss = 0.046445 | val accuracy = 94.80%\n",
      "Epoch  492: training loss = 0.046384 | val accuracy = 94.81%\n",
      "Epoch  493: training loss = 0.046323 | val accuracy = 94.81%\n",
      "Epoch  494: training loss = 0.046263 | val accuracy = 94.81%\n",
      "Epoch  495: training loss = 0.046203 | val accuracy = 94.81%\n",
      "Epoch  496: training loss = 0.046142 | val accuracy = 94.81%\n",
      "Epoch  497: training loss = 0.046082 | val accuracy = 94.82%\n",
      "Epoch  498: training loss = 0.046022 | val accuracy = 94.83%\n",
      "Epoch  499: training loss = 0.045963 | val accuracy = 94.83%\n"
     ]
    }
   ],
   "source": [
    "losses, accuracies = mnist_classifier.train(X_train, y_train, X_test, y_test, batch_size=30, num_epochs=500)\n",
    "# note: Reduce the batch size and/or number of epochs if your computer can't handle the computations / takes too long.\n",
    "#       Remember, numpy also uses the CPU, not the GPU as modern Deep Learning libraries do, hence the lack of performance here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost **95%** of accuracy! This is much better.\n",
    "\n",
    "Congratulations for implementing and training your first neural network classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the evolution of the loss and accuracy during the training, to better visualize the evolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xee97048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses, accuracies = [loss_untrained] + losses, [accuracy_untrained] + accuracies\n",
    "fig, ax_loss = plt.subplots()\n",
    "\n",
    "color = 'red'\n",
    "ax_loss.set_xlim([0, 510])\n",
    "ax_loss.set_xlabel('Epochs')\n",
    "ax_loss.set_ylabel('Training Loss', color=color)\n",
    "ax_loss.plot(losses, color=color)\n",
    "ax_loss.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax_acc = ax_loss.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'blue'\n",
    "ax_acc.set_xlim([0, 510])\n",
    "ax_acc.set_ylim([0, 1])\n",
    "ax_acc.set_ylabel('Val Accuracy', color=color)\n",
    "ax_acc.plot(accuracies, color=color)\n",
    "ax_acc.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our network *converged* quite fast, though the accuracy slowly kept increasing. It looks even like the accuracy could still go up a bit with some further training iterations... Feel free to try. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any case,this is it for chapter 1!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
