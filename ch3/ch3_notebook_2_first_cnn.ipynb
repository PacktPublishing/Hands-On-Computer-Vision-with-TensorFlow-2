{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Chapter 3: Modern Neural Networks - First CNN with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements the LeNet-5 architecture [1] as presented in the book, and applies it to hand-written digit recognition (MNIST dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As presented in [Chapter 2](../ch2), we use Tensorflow and Keras helpers to load the commonly-used [MNIST](http://yann.lecun.com/exdb/mnist) training and testing datasets. We also normalize the images (setting the pixel values from `[0, 255]` to `[0, 1]` and reshape them properly (as Tensorflow stores them as column-vectors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "img_rows, img_cols, img_ch = 28, 28, 1\n",
    "input_shape = (img_rows, img_cols, img_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], *input_shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], *input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've demonstrated how CNNs can be implemented different ways depending on the level of parametrization vs. succinctness one needs. In this case, we will use the Keras API to showcase once again how straightforward it makes the network implementation and usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5 is a simple CNN composed of 7 layers (2 *conv*, 2 *max-pool*, 3 *FC* + 1 helper layer to flatten the feature maps before the *FC*). For more details, we invite our readers to go back to Chapter 3. Here is the model's implementation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 1st block:\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 2nd block:\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Dense layers:\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying to MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compile our model for digit classification. To train it for this task, we instantiate the optimizer (a simple SGD one for this example) and define the loss (the categorical cross-entropy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before launching the training, we also instantiate some Keras callbacks, i.e., utility functions automatically called at some points during training to monitor it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # Callback to interrupt the training if the validation loss (`val_loss`) stops improving for over 3 epochs:\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss'),\n",
    "    # Callback to log the graph, losses and metrics into TensorBoard (saving log files in `./logs` directory):\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The Tensorboard callback allows us to monitor the training from Tensorboard. For that, open a console and launch the programm with the command \"`tensorboard --logdir=./logs`\". You can then access Tensorboard from a browser, via the URL \"[`localhost:6006`](localhost:6006)\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass everything to our model to train it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.5189 - acc: 0.8407 - val_loss: 0.1461 - val_acc: 0.9548\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.1364 - acc: 0.9576 - val_loss: 0.0905 - val_acc: 0.9715\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0950 - acc: 0.9707 - val_loss: 0.0696 - val_acc: 0.9776\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0761 - acc: 0.9766 - val_loss: 0.0601 - val_acc: 0.9794\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0640 - acc: 0.9798 - val_loss: 0.0498 - val_acc: 0.9840\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0561 - acc: 0.9829 - val_loss: 0.0487 - val_acc: 0.9841\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0503 - acc: 0.9845 - val_loss: 0.0455 - val_acc: 0.9860\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0452 - acc: 0.9860 - val_loss: 0.0454 - val_acc: 0.9835\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0408 - acc: 0.9878 - val_loss: 0.0459 - val_acc: 0.9856\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0368 - acc: 0.9888 - val_loss: 0.0397 - val_acc: 0.9870\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0353 - acc: 0.9887 - val_loss: 0.0420 - val_acc: 0.9857\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0317 - acc: 0.9903 - val_loss: 0.0409 - val_acc: 0.9863\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0291 - acc: 0.9909 - val_loss: 0.0386 - val_acc: 0.9868\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0277 - acc: 0.9914 - val_loss: 0.0361 - val_acc: 0.9874\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0260 - acc: 0.9921 - val_loss: 0.0430 - val_acc: 0.9860\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0241 - acc: 0.9925 - val_loss: 0.0365 - val_acc: 0.9896\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0223 - acc: 0.9931 - val_loss: 0.0352 - val_acc: 0.9884\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0210 - acc: 0.9933 - val_loss: 0.0368 - val_acc: 0.9879\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.0196 - acc: 0.9941 - val_loss: 0.0504 - val_acc: 0.9837\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.0181 - acc: 0.9948 - val_loss: 0.0373 - val_acc: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa4da780908>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          batch_size=32, epochs=30, validation_data=(x_test, y_test), \n",
    "          verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a machine with recent GPU(s), this training is quite fast (~0.16ms/step in our case, c.f. logs). The final accuracy we obtain on the validation dataset (**~98.9%!**) is also much better compared to our previous attempts with simpler networks. Indeed, the relative error has been approximately divided by 5 (from ~5% to ~1% error), which is a significant improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LeCun, Yann. \"*LeNet-5, convolutional neural networks.*\" [http://yann.lecun.com/exdb/lenet](http://yann.lecun.com/exdb/lenet) (2015): 20."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
